{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Franka Panda\n",
    "\n",
    "* 环境\n",
    "\n",
    "| Package   | Version |\n",
    "|-----------|---------|\n",
    "| gymnasium | 0.29.1  |\n",
    "| numpy | 1.24.0 |\n",
    "| scipy | 1.13.1 |\n",
    "| torch |  2.3.1+cu121 |\n",
    "| grpcio |   1.64.1 |\n",
    "| 关卡名 | franka_emika_panda |\n",
    "\n",
    "* 采用在线强化学习\n",
    "* 任务目标是达到制定目标点\n",
    "* 控制量为关节电机驱动角度，采用离散采样，每个关节生成 增加、减少、不变 三个控制信号\n",
    "* time_step 为 0.01，因此 fps 设为 100\n",
    "* frame_skip 为1， 即每次action进行1次 step，因此是 100 actions/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "current_file_path = os.path.abspath('')\n",
    "project_root = os.path.dirname(current_file_path)\n",
    "\n",
    "# 将项目根目录添加到 PYTHONPATH\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from gymnasium.envs.registration import register\n",
    "from envs.mujoco.franka_emika_panda import FrankaEnv\n",
    "from datetime import datetime\n",
    "import torch.nn as nn\n",
    "from envs.orca_gym_env import ActionSpaceType\n",
    "\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "def register_env(grpc_address, low_path_filter_alpha, update_goal_interval):\n",
    "    print(\"register_env: \", grpc_address)\n",
    "    gym.register(\n",
    "        id=f\"FrankaPanda-v0-OrcaGym-{grpc_address[-2:]}\",\n",
    "        entry_point=\"envs.mujoco.franka_emika_panda:FrankaEnv\",\n",
    "        kwargs={'frame_skip': 5, \n",
    "                'action_space_type': ActionSpaceType.DISCRETE,\n",
    "                'action_step_count': 200,\n",
    "                'grpc_address': grpc_address, \n",
    "                'agent_names': ['Panda'], \n",
    "                'time_step': 0.0166666, \n",
    "                'alpha': low_path_filter_alpha, \n",
    "                'update_goal_interval': update_goal_interval},\n",
    "        max_episode_steps=512,\n",
    "        reward_threshold=0.0,\n",
    "    )\n",
    "\n",
    "async def continue_training(env, total_timesteps, is_training):\n",
    "\n",
    "\n",
    "    # 加载已有模型或初始化新模型\n",
    "    if os.path.exists(\"frankapanda_ppo_model.zip\"):\n",
    "        model = PPO.load(\"frankapanda_ppo_model\", env=env)\n",
    "    else:\n",
    "        # 定义自定义策略网络\n",
    "        policy_kwargs = dict(\n",
    "            net_arch=dict(\n",
    "                pi=[256, 256, 256],  # 策略网络结构\n",
    "                vf=[256, 256, 256]   # 值函数网络结构\n",
    "            ),\n",
    "            ortho_init=True,\n",
    "            activation_fn=nn.ReLU\n",
    "        )\n",
    "        model = PPO(\"MlpPolicy\", env, verbose=1, learning_rate=0.0003, n_steps=2048, batch_size=128, gamma=0.99, clip_range=0.2, policy_kwargs=policy_kwargs)\n",
    "        \n",
    "\n",
    "    # 训练模型，每 LOOP_LEN 步保存一次模型\n",
    "    if (is_training):\n",
    "        LOOP_LEN = 100000\n",
    "        if (total_timesteps >= LOOP_LEN):\n",
    "            for i in range(total_timesteps // LOOP_LEN):\n",
    "                model.learn(LOOP_LEN)\n",
    "                model.save(f\"frankapanda_ppo_model_ckp{i}\")\n",
    "                print(f\"-----------------Save Model: {i}-----------------\")\n",
    "\n",
    "        model.save(\"frankapanda_ppo_model\")\n",
    "        \n",
    "\n",
    "    # 测试模型\n",
    "    observation, info = env.reset(seed=42)\n",
    "    for test in range(10):\n",
    "        total_reward = 0\n",
    "        for _ in range(1000):\n",
    "            start_time = datetime.now()\n",
    "\n",
    "            action, _states = model.predict(observation, deterministic=True)\n",
    "            observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "            total_reward += reward\n",
    "\n",
    "            # 帧率为 60fps ，为显示为正常速度，每次渲染间隔 16ms\n",
    "            elapsed_time = datetime.now() - start_time\n",
    "            if elapsed_time.total_seconds() < 0.016666666666666666:\n",
    "                await asyncio.sleep(0.016666666666666666 - elapsed_time.total_seconds())\n",
    "\n",
    "            if terminated or truncated:\n",
    "                print(f\"----------------Test: {test}----------------\")\n",
    "                print(\"Terminated: \", terminated, \" Truncated: \", truncated)\n",
    "                print(\"Total Reward: \", total_reward)\n",
    "                print(\"---------------------------------------\")\n",
    "                observation, info = env.reset()\n",
    "                total_reward = 0\n",
    "                break\n",
    "\n",
    "    env.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        grpc_address = \"localhost:50051\"\n",
    "        print(\"simulation running... , grpc_address: \", grpc_address)\n",
    "        env_id = f\"FrankaPanda-v0-OrcaGym-{grpc_address[-2:]}\"\n",
    "        low_path_filter_alpha=0.7\n",
    "        update_goal_interval=10000\n",
    "        register_env(grpc_address, low_path_filter_alpha, update_goal_interval)\n",
    "\n",
    "        env = gym.make(env_id)\n",
    "        print(\"启动仿真环境\")\n",
    "        asyncio.run(continue_training(env, total_timesteps=200000, is_training=True))\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"关闭仿真环境\")        \n",
    "        env.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试用代码\n",
    "\n",
    "* 测试控制结果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "current_file_path = os.path.abspath('')\n",
    "project_root = os.path.dirname(current_file_path)\n",
    "\n",
    "# 将项目根目录添加到 PYTHONPATH\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from gymnasium.envs.registration import register\n",
    "from envs.mujoco.franka_emika_panda import FrankaEnv\n",
    "from datetime import datetime\n",
    "import torch.nn as nn\n",
    "from envs.orca_gym_env import ActionSpaceType\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "def register_env(grpc_address, low_path_filter_alpha, update_goal_interval):\n",
    "    print(\"register_env: \", grpc_address)\n",
    "    gym.register(\n",
    "        id=f\"FrankaPanda-v0-OrcaGym-{grpc_address[-2:]}\",\n",
    "        entry_point=\"envs.mujoco.franka_emika_panda:FrankaEnv\",  # 更新为实际路径\n",
    "        kwargs={'frame_skip': 1, \n",
    "        'action_space_type': ActionSpaceType.CONTINUOUS,\n",
    "        'action_step_count': 200,\n",
    "        'grpc_address': grpc_address, \n",
    "        'agent_names': ['Panda'], \n",
    "        'time_step': 0.0166666, \n",
    "        'alpha': low_path_filter_alpha, \n",
    "        'update_goal_interval': update_goal_interval},\n",
    "        max_episode_steps=512,\n",
    "        reward_threshold=0.0,\n",
    "    )\n",
    "\n",
    "async def continue_training(env, total_timesteps, is_training):\n",
    "    # 测试模型\n",
    "    observation, info = env.reset(seed=42)\n",
    "    for test in range(10):\n",
    "        total_reward = 0\n",
    "\n",
    "        action =  np.array([0, -1,  0, -2, 0,  1.5, 2, 0, 0])\n",
    "        mean = 0\n",
    "        std_dev = 0.1\n",
    "\n",
    "        for _ in range(1000):\n",
    "            start_time = datetime.now()\n",
    "\n",
    "            # 使用高斯噪声修改 action 数组\n",
    "            noise = np.random.normal(mean, std_dev, action.shape)\n",
    "            action = action + noise\n",
    "\n",
    "            # action = [0, 0, 0, 0, 0, 0, 0]\n",
    "            observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "            # 帧率为 60fps ，为显示为正常速度，每次渲染间隔 16ms\n",
    "            elapsed_time = datetime.now() - start_time\n",
    "            if elapsed_time.total_seconds() < 0.016:\n",
    "                await asyncio.sleep(0.016 - elapsed_time.total_seconds())\n",
    "\n",
    "    env.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        grpc_address = 'localhost:50051'\n",
    "        print(\"simulation running... , grpc_address: \", grpc_address)\n",
    "        env_id = f\"FrankaPanda-v0-OrcaGym-{grpc_address[-2:]}\"\n",
    "        register_env(grpc_address, low_path_filter_alpha=0.5, update_goal_interval=10000)\n",
    "\n",
    "        env = gym.make(env_id)      \n",
    "        print(\"启动仿真环境\")\n",
    "        asyncio.run(continue_training(env, total_timesteps=100000, is_training=True))\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"关闭仿真环境\")        \n",
    "        env.close()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "orca_gym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
